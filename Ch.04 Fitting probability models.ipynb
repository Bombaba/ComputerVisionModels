{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems 4.1\n",
    "\n",
    "**Show that the maximum likelihood solution for the variance $\\sigma^2$ of the normal distribution is given by**\n",
    "\n",
    "\\begin{equation*}\n",
    "  \\sigma^2 = \\displaystyle\\sum_{i=1}^I \\frac{(x_i - \\hat{\\mu})^2}{I}.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  \\sigma^2\n",
    "   &= \\operatorname*{argmax}_{\\sigma^2} \\left[Pr(x_{1\\dots I}|\\hat{\\mu}, \\sigma^2)\\right] \\\\\n",
    "   &= \\operatorname*{argmax}_{\\sigma^2} \\left[\\prod_{i=1}^{I}\\mathrm{Norm}_{x_i}[\\mu, \\sigma^2]\\right] \\\\\n",
    "   &= \\operatorname*{argmax}_{\\sigma^2} \\left[\\ln\\prod_{i=1}^{I} \\mathrm{Norm}_{x_i}[\\mu, \\sigma^2]\\right] \\\\\n",
    "   &= \\operatorname*{argmax}_{\\sigma^2} \\left[\\sum_{i=1}^{I}\\ln\\left[\\mathrm{Norm}_{x_i}[\\mu, \\sigma^2]\\right]\\right] \\\\\n",
    "   &= \\operatorname*{argmax}_{\\sigma^2} \\left[-\\frac{I}{2}\\ln[2\\pi] - \\frac{I}{2}\\ln[\\sigma^2] - \\frac{1}{2\\sigma^2}\\sum_{i=1}^I(x_i - \\hat{\\mu})^2\\right] \\\\\n",
    "   &= \\operatorname*{argmax}_{\\sigma^2} \\left[-\\frac{I}{2}\\ln[\\sigma^2] - \\frac{1}{2\\sigma^2}\\sum_{i=1}^I(x_i - \\hat{\\mu})^2\\right] \\\\\n",
    "   &= \\operatorname*{argmin}_{\\sigma^2} \\left[I\\ln[\\sigma^2] + \\frac{1}{\\sigma^2}\\sum_{i=1}^I(x_i - \\hat{\\mu})^2\\right] \\\\\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Define $L = I\\ln[\\sigma^2] + \\frac{1}{\\sigma^2}\\sum_{i=1}^I(x_i - \\hat{\\mu})^2$, then the stational point of $L$ regarding $\\sigma^2$ is led as\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  &\\frac{\\partial L}{\\partial \\sigma^2} = \\frac{I}{\\sigma^2} - \\frac{1}{(\\sigma^2)^2}\\sum_{i=1}^I(x_i - \\hat{\\mu})^2\\ = 0 \\\\\n",
    "  &\\implies \\sigma^2 = \\sum_{i=1}^I \\frac{(x_i - \\hat{\\mu})^2}{I}\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 4.2\n",
    "\n",
    "Show that the MAP solution for the mean $\\mu$ and variance $\\sigma^2$ of the normal distribution is given by\n",
    "\n",
    "\\begin{equation*}\n",
    "  \\hat{\\mu} = \\frac{\\sum_{i=1}^{I}x_i + \\gamma\\delta}{I + \\gamma}\n",
    "  \\quad \\text{and} \\quad\n",
    "  \\hat{\\sigma^2} = \\frac{\\sum_{i=1}^{I}(x_i - \\hat{\\mu})^2 + 2\\beta + \\gamma(\\delta - \\hat{\\mu})^2}{I + 3 + 2\\alpha},\n",
    "\\end{equation*}\n",
    "\n",
    "when we use the conjugate normal-scaled inverse gamma prior\n",
    "\n",
    "\\begin{equation*}\n",
    "  Pr(\\mu, \\sigma^2) =\n",
    "  \\frac{\\sqrt{\\gamma}}{\\sigma\\sqrt{2\\pi}}\n",
    "  \\frac{\\beta^{\\alpha}}{\\Gamma[\\alpha]}\\left(\\frac{1}{\\sigma^2}\\right)^{\\alpha+1}\n",
    "  \\exp\\left[-\\frac{2\\beta + \\gamma(\\delta - \\mu)^2}{2\\sigma^2}\\right].\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters $\\hat{\\mu}, \\hat{\\sigma^2}$ estimated by MAP is\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  \\hat{\\mu}, \\hat{\\sigma^2}\n",
    "  &= \\operatorname*{argmax}_{\\mu, \\sigma^2} \\left[Pr(x_{i\\dots I} | \\mu, \\sigma^2) Pr(\\mu, \\sigma^2)\\right]\\\\\n",
    "  &= \\operatorname*{argmax}_{\\mu, \\sigma^2} \\left[\\prod_{i=1}^{I}\\text{Norm}_{x_i}(\\mu, \\sigma^2) \\cdot \\text{NormInvGam}_{\\mu, \\sigma^2}[\\alpha, \\beta, \\gamma, \\delta]\\right] \\\\\n",
    "  &= \\operatorname*{argmax}_{\\mu, \\sigma^2} \\left[\\ln\\left[\\prod_{i=1}^{I}\\text{Norm}_{x_i}(\\mu, \\sigma^2) \\cdot \\text{NormInvGam}_{\\mu, \\sigma^2}[\\alpha, \\beta, \\gamma, \\delta]\\right]\\right] \\\\\n",
    "  &= \\operatorname*{argmax}_{\\mu, \\sigma^2} \\left[\\sum_{i=1}^{I}\\ln\\left[\\text{Norm}_{x_i}(\\mu, \\sigma^2)\\right]+ \\ln\\left[\\text{NormInvGam}_{\\mu, \\sigma^2}[\\alpha, \\beta, \\gamma, \\delta]\\right]\\right] \\\\\n",
    "  &= \\operatorname*{argmax}_{\\mu, \\sigma^2} \\left[-\\frac{I}{2}\\ln[2\\pi] - \\frac{I}{2}\\ln[\\sigma^2] - \\frac{\\sum_{i=1}^{I}(x_i - \\mu)^2}{2\\sigma^2} + \\ln\\left[\\frac{\\sqrt{r}}{\\sqrt{2\\pi}}\\frac{\\beta^{\\alpha}}{\\Gamma[\\alpha]}\\right] - \\left(\\alpha + \\frac{3}{2}\\right)\\ln[\\sigma^2] - \\frac{2\\beta + \\gamma(\\delta - \\mu)^2}{2\\sigma^2}\\right] \\\\\n",
    "  &= \\operatorname*{argmax}_{\\mu, \\sigma^2} \\left[-\\frac{1}{2}(I + 3 + 2\\alpha)\\ln[\\alpha^2] - \\frac{\\sum_{i=1}^{I}(x_i - \\mu)^2 + 2\\beta + \\gamma(\\delta - \\mu)^2}{2\\sigma^2}\\right]\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If we let $L = -(I + 3 + 2\\alpha)\\ln[\\alpha^2]/2 - (\\sum_{i=1}^{I}(x_i - \\mu)^2 + 2\\beta + \\gamma(\\delta - \\mu)^2) / 2\\sigma^2$, the stationary point in terms of $\\mu$ and $\\sigma^2$ is the point where the derivatives with respect to $\\mu$ and $\\sigma^2$ is zero.\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  \\frac{\\partial L}{\\partial \\mu}\\bigg\\vert_{\\mu = \\hat{\\mu}, \\sigma^2 = \\hat{\\sigma^2}} &= \\frac{\\sum_{i=1}^{I}(x_i - \\hat{\\mu}) + \\gamma(\\delta - \\hat{\\mu})}{\\hat{\\sigma^2}} = 0 \\\\\n",
    "  \\therefore \\hat{\\mu} &= \\frac{\\sum_{i=1}^{I}x_i + \\gamma\\delta}{I + \\gamma}.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  \\frac{\\partial L}{\\partial \\sigma^2}\\bigg\\vert_{\\mu = \\hat{\\mu}, \\sigma^2 = \\hat{\\sigma^2}} &= -\\frac{1}{2}(I + 3 + 2\\alpha)\\frac{1}{\\hat{\\sigma^2}} + \\frac{\\sum_{i=1}^{I}(x_i - \\hat{\\mu})^2 + 2\\beta + \\gamma(\\delta - \\hat{\\mu})^2}{2\\hat{\\sigma^4}} = 0 \\\\\n",
    "  \\therefore   \\hat{\\sigma^2} &= \\frac{\\sum_{i=1}^{I}(x_i - \\hat{\\mu})^2 + 2\\beta + \\gamma(\\delta - \\hat{\\mu})^2}{I + 3 + 2\\alpha}.\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 4.3\n",
    "\n",
    "**Taking equation 4.29 as a starting point, show that the maximum liklihood parameters for the categorical distribution are given by**\n",
    "\n",
    "\\begin{equation*}\n",
    "  \\hat{\\lambda}_k = \\frac{N_k}{\\sum_{m=1}^6N_m},\n",
    "\\end{equation*}\n",
    "\n",
    "**where $N_k$ is the number of times that category $K$ was observed in the training data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the equation 4.29:\n",
    "\n",
    "\\begin{equation}\n",
    "  L = \\sum_{k=1}^6 N_k\\ln[\\lambda_k] + \\nu\\left(\\sum_{k=1}^6 \\lambda_k-1\\right)\n",
    "\\end{equation}\n",
    "\n",
    "The necessary conditions for the maxima of the objective function are that the derivatives with respect to $\\lambda_k$ and $\\nu$ equals zero.  We will solve the equation\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  &\\frac{\\partial L}{\\partial \\lambda_k}\\bigg\\vert_{\\lambda_k = \\hat{\\lambda}_k} = \\frac{N_k}{\\hat{\\lambda}_k} + \\nu = 0 \\\\\n",
    "  &\\implies \\hat{\\lambda}_k = -\\frac{N_k}{\\nu}.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Then we can obtain $\\nu$ from the condition $\\sum_m \\lambda_m = 1$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  &\\sum_{m=1}^6 \\hat{\\lambda}_m = -\\frac{\\sum_{m=1}^6 N_m}{\\nu} = 1 \\\\\n",
    "  &\\implies \\nu = -\\sum_{m=1}^6 N_m.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Hence,\n",
    "\n",
    "\\begin{equation}\n",
    "  \\hat{\\lambda}_k = \\frac{N_k}{\\sum_{m=1}^6N_m}.\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4.4\n",
    "\n",
    "**Show that the MAP estimate for the parameters $\\{\\lambda_k\\}_{k=1}^K$ of the categorical distribution is given by**\n",
    "\n",
    "\\begin{equation*}\n",
    "  \\hat{\\lambda}_k = \\frac{N_k + \\alpha_k - 1}{\\sum_{m=1}^K(N_m + \\alpha_m - 1)}, \n",
    "\\end{equation*}\n",
    "\n",
    "**under the assumption of a Dirichlet prior with hyperparameters $\\{\\alpha_k\\}_{k=1}^K$.  The terms $N_k$ again indicate the number of times that category $k$ was observed in the training data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the MAP estimate of categorical distribution,\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  \\hat{\\lambda}_{1 \\dots K}\n",
    "  &= \\operatorname*{argmax}_{\\lambda_{1 \\dots K}}\\left[Pr(x_{1 \\dots I}|\\lambda_{1 \\dots K})Pr(\\lambda_{1 \\dots K})\\right] \\\\\n",
    "  &= \\operatorname*{argmax}_{\\lambda_{1 \\dots K}}\\left[\\prod_{i=1}^I\\mathrm{Cat}_{x_i}[\\lambda_{1 \\dots K}] \\cdot \\mathrm{Dir}_{\\lambda_{1 \\dots K}}[\\alpha_{1 \\dots K}]\\right] \\\\\n",
    "  &= \\operatorname*{argmax}_{\\lambda_{1 \\dots K}}\\left[\\ln\\left[\\prod_{i=1}^I\\mathrm{Cat}_{x_i}[\\lambda_{1 \\dots K}] \\cdot \\mathrm{Dir}_{\\lambda_{1 \\dots K}}[\\alpha_{1 \\dots K}]\\right]\\right] \\\\\n",
    "  &= \\operatorname*{argmax}_{\\lambda_{1 \\dots K}}\\left[\\sum_{i=1}^I\\ln\\left[\\mathrm{Cat}_{x_i}[\\lambda_{1 \\dots K}]\\right] + \\ln\\left[ \\mathrm{Dir}_{\\lambda_{1 \\dots K}}[\\alpha_{1 \\dots K}]\\right]\\right] \\\\\n",
    "  &= \\operatorname*{argmax}_{\\lambda_{1 \\dots K}}\\left[\\sum_{k=1}^K N_k\\ln[\\lambda_k] + \\ln\\left[\\frac{\\Gamma[\\sum_k\\alpha_k]}{\\prod_k\\Gamma[\\alpha_k]}\\right] + \\sum_{k=1}^K(\\alpha_k - 1)\\ln[\\lambda_k]\\right] \\\\\n",
    "  &= \\operatorname*{argmax}_{\\lambda_{1 \\dots K}}\\left[\\sum_{k=1}^K (N_k + \\alpha_k - 1)\\ln[\\lambda_k]\\right] \\qquad \\text{s.t.} \\; \\sum_{k=1}^K\\lambda_k = 1.\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define $L$ according to the Lagrange multiplier:\n",
    "\n",
    "\\begin{equation}\n",
    "  L = \\sum_{k=1}^K (N_k + \\alpha_k - 1)\\ln[\\lambda_k] + \\nu\\left(\\sum_{k=1}^K\\lambda_k - 1\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The necessary condition for the maxima of the objective function is that the derivative with respect to $\\lambda_k$ equals zero:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  &\\frac{\\partial L}{\\partial \\lambda_k}\\bigg\\vert_{\\lambda_k = \\hat{\\lambda}_k} = \\frac{N_k + \\alpha_k - 1}{\\hat{\\lambda}_k} + \\nu = 0 \\\\\n",
    "  &\\implies \\hat{\\lambda}_k = -\\frac{N_k + \\alpha_k - 1}{\\nu}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "We can obtain $\\nu$ from the condition $\\sum_m\\lambda_m = 1$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  &\\sum_{m=1}^{K}\\hat{\\lambda}_m = -\\frac{\\sum_{m=1}^K(N_m + \\alpha_m - 1)}{\\nu} = 1 \\\\\n",
    "  &\\implies \\nu = -\\sum_{m=1}^K(N_m + \\alpha_m - 1)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Hence,\n",
    "\n",
    "\\begin{equation*}\n",
    "  \\hat{\\lambda}_k = \\frac{N_k + \\alpha_k - 1}{\\sum_{m=1}^K(N_m + \\alpha_m - 1)}, \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
